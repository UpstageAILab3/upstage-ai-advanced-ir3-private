1. **베이스라인**  
   

2. **baseline_code실행 bongsoomoco-sentencedistilbertV2.1**  
   

3. **basicmodel_preprocessing_3**  
   

4. **baseline_translated**  
   역색인 구조로 검색할 때, 특히 고유명사에서 한국어-영어 간 매칭이 되지 않는 문제가 발생했습니다.  
   이를 해결하기 위해 사용자의 질문과 참조 문서의 언어를 통일시켜야 했습니다.  
   LLM 번역을 활용해 `eval`과 `documents` 파일을 영어로 번역했으며, 벡터 검색을 위해 MTEB 리더보드 상위권에 있는 적절한 크기의 모델로 변경했습니다.  
   (추후 Qwen 모델에 대한 추가 학습이 필요함)  
   **MAP** 점수: **0.6242**

5. **baseline_translated(벡터 유사도)**  
   동일한 조건에서 벡터 검색을 진행했습니다.  
   임베딩 모델의 크기가 커지고, 언어가 통일되었기 때문에 베이스라인보다 점수가 향상될 것이라 기대했으나, 예상과는 달리 그렇지 않았습니다.  
   **MAP** 점수: **0.6606**

6. **GPT4o_Kor_KnowledgeExpert_description_modified_2**  
   

7. **prompt_engineering_다방면전문가_gpt4o**  
   

8. **FAISS, ES_Flat_cosine_add '?'**  
   벡터 DB의 인덱싱 방식과 유사도 계산 방식을 변경했습니다.  
   서비스에서 처리 속도와 비용도 중요한 요소이지만, 이번 실험에서는 오로지 정확성 향상에 초점을 맞췄습니다.  
   인덱싱은 기존의 ANN 알고리즘 대신 모든 문서를 비교하는 brute-force 방식으로 변경했고, 유사도 측정 방식은 고차원 임베딩 모델을 사용하기 때문에 l2norm에서 cosine 유사도로 변경했습니다.  
   **MAP** 점수: **0.5697**  
   실험 중 우연히 쿼리에 `?` 문자를 붙이면 더 정확한 문서가 반환되는 것을 발견했습니다.  
   `?`를 추가한 쿼리로 실험을 진행한 결과, **MAP** 점수: **0.6727**

9. **dense_retriever, LLM ensemble**  
   유사도 기반 검색의 성능이 만족스럽지 않아, LLM을 앙상블하는 방법을 시도했습니다.  
   gpt-4o mini의 비용이 저렴하여 적용해 볼 가치가 있다고 판단했습니다.  
   유사도 기반으로 상위 20개의 문서를 LLM을 통해 관련도 순으로 재정렬했습니다.  
   그러나 성능 향상은 크지 않았습니다.  
   **MAP** 점수: **0.6636**

10. **upstage_api_denseretriever**  
   데이터셋을 한글로 변경한 후, 최신 모델을 찾아본 결과, Upstage의 임베딩 모델이 가장 높은 성능을 보여 선택했습니다.  
   API로 진행한 만큼 비용은 증가했으나, 더 큰 모델을 사용할 수 있었습니다.  
   이 모델은 4096차원으로 변환하므로 Elasticsearch 8.8버전은 지원하지 않았고, FAISS로 변경하려다가 Elasticsearch 8.11+ 버전이 4096차원의 벡터를 지원함을 확인하고 업데이트하여 해결했습니다.  
   **MAP** 점수: **0.8394**  
   큰 성능 향상이 있었습니다.

11. **ensemble(sparse+dense)**  
   

12. **upstage_api_dense_add '?'**  
   쿼리에 `?`를 추가하고 Upstage 임베딩 모델을 사용해 임베딩을 진행했습니다.  
   **MAP** 점수: **0.8750**

13. **gpt4o_upstage_dense_+?+prompt**  
   

14. **HyDE(instruct, finetuning)**  
   

15. **multi_query**  